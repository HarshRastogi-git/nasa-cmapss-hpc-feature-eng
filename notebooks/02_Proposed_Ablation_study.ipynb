{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78814cbf-7f56-4972-b51b-1753ea1cb89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed pipeline configuration loaded.\n",
      "RANDOM_STATE = 42\n",
      "WINDOW_SIZE  = 30\n",
      "STRIDE       = 1\n",
      "# variables for fslope / LF-ER: 24\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 (Proposed Pipeline) – Imports & configuration\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# FFT for LF-ER feature\n",
    "from numpy.fft import rfft\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "WINDOW_SIZE = 30\n",
    "STRIDE = 1\n",
    "\n",
    "# Small epsilon for numerical stability (shared by fslope and LF-ER)\n",
    "EPSILON = 1e-6\n",
    "\n",
    "SENSOR_COLS = [f\"s_{i}\" for i in range(1, 22)]  # s_1 ... s_21\n",
    "SETTING_COLS = [\"os_1\", \"os_2\", \"os_3\"]\n",
    "\n",
    "ALL_VAR_COLS = SENSOR_COLS + SETTING_COLS\n",
    "\n",
    "print(\"Proposed pipeline configuration loaded.\")\n",
    "print(f\"RANDOM_STATE = {RANDOM_STATE}\")\n",
    "print(f\"WINDOW_SIZE  = {WINDOW_SIZE}\")\n",
    "print(f\"STRIDE       = {STRIDE}\")\n",
    "print(f\"# variables for fslope / LF-ER: {len(ALL_VAR_COLS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41408938-1da3-4213-8c4f-9a27a0c3cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD001 data loaded and labeled.\n",
      "train_raw shape       : (20631, 26)\n",
      "test_raw shape        : (13096, 26)\n",
      "rul_test_final shape  : (100, 1)\n",
      "train_labeled shape   : (20631, 27)\n",
      "test_last_labeled shape (one row per engine): (100, 27)\n",
      "Data loading & labeling time: 0.398 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 – Load FD001 and prepare RUL labels\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# File paths (adjust these if your folder structure is different)\n",
    "# -------------------------------------------------------------------\n",
    "TRAIN_PATH = \"C:/Users/hrast/OneDrive/Desktop/Minor Project/CMaps/train_FD001.txt\"\n",
    "TEST_PATH  = \"C:/Users/hrast/OneDrive/Desktop/Minor Project/CMaps/test_FD001.txt\"\n",
    "RUL_PATH   = \"C:/Users/hrast/OneDrive/Desktop/Minor Project/CMaps/RUL_FD001.txt\"\n",
    "\n",
    "\n",
    "def load_fd001(train_path=TRAIN_PATH, test_path=TEST_PATH, rul_path=RUL_PATH):\n",
    "    \"\"\"\n",
    "    Load the NASA C-MAPSS FD001 dataset:\n",
    "      - training trajectories,\n",
    "      - test trajectories,\n",
    "      - final RUL values for each test engine.\n",
    "    \"\"\"\n",
    "    col_names = (\n",
    "        [\"unit_nr\", \"time_cycles\"] +\n",
    "        [f\"os_{i}\" for i in range(1, 4)] +      # os_1, os_2, os_3\n",
    "        [f\"s_{i}\" for i in range(1, 22)]        # s_1 ... s_21\n",
    "    )\n",
    "\n",
    "    # sep=r\"\\s+\" handles variable whitespace between columns\n",
    "    train_raw = pd.read_csv(train_path, sep=r\"\\s+\", header=None)\n",
    "    test_raw  = pd.read_csv(test_path,  sep=r\"\\s+\", header=None)\n",
    "\n",
    "    # In case there are extra trailing empty columns, trim to expected length\n",
    "    if train_raw.shape[1] > len(col_names):\n",
    "        train_raw = train_raw.iloc[:, :len(col_names)]\n",
    "    if test_raw.shape[1] > len(col_names):\n",
    "        test_raw = test_raw.iloc[:, :len(col_names)]\n",
    "\n",
    "    train_raw.columns = col_names\n",
    "    test_raw.columns  = col_names\n",
    "\n",
    "    # RUL for test engines (one row per engine)\n",
    "    rul_test_final = pd.read_csv(rul_path, sep=r\"\\s+\", header=None)\n",
    "    rul_test_final.columns = [\"RUL\"]\n",
    "\n",
    "    return train_raw, test_raw, rul_test_final\n",
    "\n",
    "\n",
    "def add_rul_to_train(train_df):\n",
    "    \"\"\"\n",
    "    For each unit_nr in the training set, compute remaining useful life (RUL):\n",
    "\n",
    "        RUL(t) = max_cycle(unit) - time_cycles(t)\n",
    "\n",
    "    and append it as a new column 'RUL'.\n",
    "    \"\"\"\n",
    "    train_df = train_df.copy()\n",
    "    max_cycles = train_df.groupby(\"unit_nr\")[\"time_cycles\"].transform(\"max\")\n",
    "    train_df[\"RUL\"] = max_cycles - train_df[\"time_cycles\"]\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def get_test_final_cycles(test_df, rul_df):\n",
    "    \"\"\"\n",
    "    For the test set:\n",
    "      - find the last observed cycle for each engine,\n",
    "      - keep only that row,\n",
    "      - attach the corresponding RUL from rul_df.\n",
    "\n",
    "    Returns a DataFrame with exactly one row per test engine.\n",
    "    \"\"\"\n",
    "    # Index of last cycle for each unit\n",
    "    idx_last = test_df.groupby(\"unit_nr\")[\"time_cycles\"].idxmax()\n",
    "    test_last = test_df.loc[idx_last].copy()\n",
    "\n",
    "    # Sort by unit_nr to align with RUL file ordering\n",
    "    test_last = test_last.sort_values(\"unit_nr\").reset_index(drop=True)\n",
    "    test_last[\"RUL\"] = rul_df[\"RUL\"].values\n",
    "\n",
    "    return test_last\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Actually load data and build labeled train/test summaries\n",
    "# -------------------------------------------------------------------\n",
    "start_time = time.time()\n",
    "\n",
    "train_raw, test_raw, rul_test_final = load_fd001()\n",
    "train_labeled = add_rul_to_train(train_raw)\n",
    "test_last_labeled = get_test_final_cycles(test_raw, rul_test_final)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"FD001 data loaded and labeled.\")\n",
    "print(f\"train_raw shape       : {train_raw.shape}\")\n",
    "print(f\"test_raw shape        : {test_raw.shape}\")\n",
    "print(f\"rul_test_final shape  : {rul_test_final.shape}\")\n",
    "print(f\"train_labeled shape   : {train_labeled.shape}\")\n",
    "print(f\"test_last_labeled shape (one row per engine): {test_last_labeled.shape}\")\n",
    "print(f\"Data loading & labeling time: {end_time - start_time:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c206505e-53f2-4e98-8a30-ad7bff968714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fslope helpers and rolling feature generators are defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 – fslope (normalized windowed trend slope) feature extraction\n",
    "\n",
    "def compute_fslope(x_window, t_idx, t_mean, denom_t, epsilon=EPSILON):\n",
    "    \"\"\"\n",
    "    Compute the normalized windowed trend slope (fslope) for a 1D window.\n",
    "\n",
    "    We fit a simple linear regression:\n",
    "        x ≈ alpha + beta * t\n",
    "    with equally spaced t indices (0, 1, ..., w-1).\n",
    "\n",
    "    Slope beta is normalized by the mean magnitude of x in the window:\n",
    "        fslope = beta / (|mean(x)| + epsilon)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_window : array-like, shape (w,)\n",
    "        Values of a single sensor/setting in the current window.\n",
    "    t_idx : np.ndarray, shape (w,)\n",
    "        Precomputed time indices for the window (0..w-1).\n",
    "    t_mean : float\n",
    "        Mean of t_idx.\n",
    "    denom_t : float\n",
    "        Sum of squared deviations of t_idx: sum((t - t_mean)^2).\n",
    "    epsilon : float\n",
    "        Small constant to avoid division by zero.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fslope : float\n",
    "        Normalized windowed slope for this window.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x_window, dtype=np.float64)\n",
    "    x_mean = x.mean()\n",
    "\n",
    "    # Numerator of slope beta: sum( (t - t_mean) * (x - x_mean) )\n",
    "    num = np.dot(t_idx - t_mean, x - x_mean)\n",
    "    beta = num / (denom_t + 1e-12)\n",
    "\n",
    "    # Normalized slope\n",
    "    fslope = beta / (np.abs(x_mean) + epsilon)\n",
    "    return fslope\n",
    "\n",
    "\n",
    "def generate_rolling_features_for_unit_fslope(\n",
    "    df_unit,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    "):\n",
    "    \"\"\"\n",
    "    Per-unit rolling feature generator with baseline stats + fslope.\n",
    "\n",
    "    For a single engine (unit_nr), this function:\n",
    "      - sorts by time_cycles,\n",
    "      - uses a sliding window of length `window` and step `stride`,\n",
    "      - for EACH variable in SENSOR_COLS + SETTING_COLS:\n",
    "          * computes baseline statistics:\n",
    "                mean, std, min, max, skew, kurtosis\n",
    "          * additionally computes fslope (normalized trend slope),\n",
    "      - labels each window with the RUL at the last cycle in the window,\n",
    "      - records unit_nr and time_cycles of the last cycle.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_df : pd.DataFrame\n",
    "        One row per window, with columns:\n",
    "          - 'unit_nr', 'time_cycles'\n",
    "          - baseline stats for each variable\n",
    "          - '{var}_fslope' for each variable\n",
    "          - 'RUL' (label at last cycle in window)\n",
    "    \"\"\"\n",
    "    df_unit = df_unit.sort_values(\"time_cycles\").reset_index(drop=True)\n",
    "    n_cycles = len(df_unit)\n",
    "\n",
    "    if n_cycles < window:\n",
    "        # Not enough cycles to form a single window\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Precompute time indices for the regression (0, 1, ..., window-1)\n",
    "    t_idx = np.arange(window, dtype=np.float64)\n",
    "    t_mean = t_idx.mean()\n",
    "    denom_t = np.sum((t_idx - t_mean) ** 2)\n",
    "\n",
    "    rows = []\n",
    "    var_cols = SENSOR_COLS + SETTING_COLS\n",
    "\n",
    "    for start in range(0, n_cycles - window + 1, stride):\n",
    "        end = start + window\n",
    "        window_df = df_unit.iloc[start:end]\n",
    "\n",
    "        last_row = window_df.iloc[-1]\n",
    "        row_dict = {\n",
    "            \"unit_nr\": last_row[\"unit_nr\"],\n",
    "            \"time_cycles\": last_row[\"time_cycles\"],\n",
    "        }\n",
    "\n",
    "        # Compute features for each variable in the window\n",
    "        for col in var_cols:\n",
    "            x = window_df[col].values.astype(np.float64)\n",
    "\n",
    "            # Baseline rolling stats\n",
    "            x_mean = x.mean()\n",
    "            x_std = x.std(ddof=0)\n",
    "            x_min = x.min()\n",
    "            x_max = x.max()\n",
    "            x_skew = skew(x)\n",
    "            x_kurt = kurtosis(x)\n",
    "\n",
    "            row_dict[f\"{col}_mean\"] = x_mean\n",
    "            row_dict[f\"{col}_std\"] = x_std\n",
    "            row_dict[f\"{col}_min\"] = x_min\n",
    "            row_dict[f\"{col}_max\"] = x_max\n",
    "            row_dict[f\"{col}_skew\"] = x_skew\n",
    "            row_dict[f\"{col}_kurt\"] = x_kurt\n",
    "\n",
    "            # New fslope feature\n",
    "            row_dict[f\"{col}_fslope\"] = compute_fslope(\n",
    "                x_window=x,\n",
    "                t_idx=t_idx,\n",
    "                t_mean=t_mean,\n",
    "                denom_t=denom_t,\n",
    "                epsilon=epsilon,\n",
    "            )\n",
    "\n",
    "        # RUL label taken at the last cycle in the window\n",
    "        row_dict[\"RUL\"] = last_row[\"RUL\"]\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "    features_df = pd.DataFrame(rows)\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def generate_rolling_features_fslope(\n",
    "    df,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper over generate_rolling_features_for_unit_fslope for all engines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Full labeled dataset (e.g., train_labeled or test_with_dummy_rul),\n",
    "        containing 'unit_nr', 'time_cycles', 'RUL', SENSOR_COLS, SETTING_COLS.\n",
    "    window : int\n",
    "        Sliding window length (same as baseline).\n",
    "    stride : int\n",
    "        Sliding window step (same as baseline).\n",
    "    epsilon : float\n",
    "        Small constant for fslope normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_all : pd.DataFrame\n",
    "        Concatenation of per-unit features, sorted by unit_nr and time_cycles.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "\n",
    "    for unit_id, df_unit in df.groupby(\"unit_nr\"):\n",
    "        feats_unit = generate_rolling_features_for_unit_fslope(\n",
    "            df_unit,\n",
    "            window=window,\n",
    "            stride=stride,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "        if not feats_unit.empty:\n",
    "            all_features.append(feats_unit)\n",
    "\n",
    "    if not all_features:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    features_all = pd.concat(all_features, axis=0, ignore_index=True)\n",
    "    features_all = features_all.sort_values([\"unit_nr\", \"time_cycles\"]).reset_index(drop=True)\n",
    "    return features_all\n",
    "\n",
    "\n",
    "print(\"fslope helpers and rolling feature generators are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da40f3d5-f0ef-49c9-b75c-8a9d771ea9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\4161080762.py:106: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_skew = skew(x)\n",
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\4161080762.py:107: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_kurt = kurtosis(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope) TRAIN feature extraction completed.\n",
      "Proposed (fslope) TRAIN feature extraction time: 665.316 seconds\n",
      "train_features_fslope shape: (17731, 171)\n",
      "Number of features (proposed fslope): 168\n",
      "Example feature columns (first 15):\n",
      "['s_1_mean', 's_1_std', 's_1_min', 's_1_max', 's_1_skew', 's_1_kurt', 's_1_fslope', 's_2_mean', 's_2_std', 's_2_min', 's_2_max', 's_2_skew', 's_2_kurt', 's_2_fslope', 's_3_mean']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Train feature extraction with fslope (proposed pipeline)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate sliding-window features with baseline stats + fslope\n",
    "train_features_fslope = generate_rolling_features_fslope(\n",
    "    train_labeled,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "fslope_train_time = end_time - start_time\n",
    "\n",
    "print(\"Proposed (fslope) TRAIN feature extraction completed.\")\n",
    "print(f\"Proposed (fslope) TRAIN feature extraction time: {fslope_train_time:.3f} seconds\")\n",
    "print(f\"train_features_fslope shape: {train_features_fslope.shape}\")\n",
    "\n",
    "# Inspect feature columns (exclude ID/label columns)\n",
    "non_feature_cols_fslope = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "feature_cols_fslope = [c for c in train_features_fslope.columns if c not in non_feature_cols_fslope]\n",
    "\n",
    "print(f\"Number of features (proposed fslope): {len(feature_cols_fslope)}\")\n",
    "print(\"Example feature columns (first 15):\")\n",
    "print(feature_cols_fslope[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1375f8b1-798f-4793-80a3-e605ddb6dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope) design matrix constructed.\n",
      "X_fslope shape      : (17731, 168)\n",
      "y_fslope shape      : (17731,)\n",
      "groups_fslope shape : (17731,)\n",
      "Number of features (fslope): 168\n",
      "Example feature columns (first 15):\n",
      "['s_1_mean', 's_1_std', 's_1_min', 's_1_max', 's_1_skew', 's_1_kurt', 's_1_fslope', 's_2_mean', 's_2_std', 's_2_min', 's_2_max', 's_2_skew', 's_2_kurt', 's_2_fslope', 's_3_mean']\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 – Build X, y, groups for the fslope-augmented proposed pipeline\n",
    "\n",
    "# If for some reason feature_cols_fslope is not defined (e.g., you re-run cells out of order),\n",
    "# we reconstruct it here to be robust.\n",
    "non_feature_cols_fslope = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "if \"feature_cols_fslope\" not in globals():\n",
    "    feature_cols_fslope = [\n",
    "        c for c in train_features_fslope.columns\n",
    "        if c not in non_feature_cols_fslope\n",
    "    ]\n",
    "\n",
    "# Design matrix (features), target (RUL), and groups (unit_nr)\n",
    "X_fslope = train_features_fslope[feature_cols_fslope].values\n",
    "y_fslope = train_features_fslope[\"RUL\"].values\n",
    "groups_fslope = train_features_fslope[\"unit_nr\"].values\n",
    "\n",
    "print(\"Proposed (fslope) design matrix constructed.\")\n",
    "print(f\"X_fslope shape      : {X_fslope.shape}\")\n",
    "print(f\"y_fslope shape      : {y_fslope.shape}\")\n",
    "print(f\"groups_fslope shape : {groups_fslope.shape}\")\n",
    "print(f\"Number of features (fslope): {len(feature_cols_fslope)}\")\n",
    "print(\"Example feature columns (first 15):\")\n",
    "print(feature_cols_fslope[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca3e491-da81-40f5-9ade-d00f524d1f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE = 38.298, MAE = 23.874\n",
      "Fold 2: RMSE = 32.603, MAE = 20.757\n",
      "Fold 3: RMSE = 31.603, MAE = 20.011\n",
      "Fold 4: RMSE = 33.677, MAE = 22.375\n",
      "Fold 5: RMSE = 30.326, MAE = 20.997\n",
      "\n",
      "Proposed (fslope) CV results:\n",
      "  RMSE mean = 33.301, std = 2.732\n",
      "  MAE  mean = 21.603, std = 1.369\n",
      "Proposed (fslope) CV time (5 folds): 17.535 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 – GroupKFold CV with XGBoost (proposed fslope features)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Root Mean Squared Error.\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "rmse_scores_fslope = []\n",
    "mae_scores_fslope = []\n",
    "\n",
    "cv_start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    gkf.split(X_fslope, y_fslope, groups_fslope), start=1\n",
    "):\n",
    "    X_tr, X_val = X_fslope[train_idx], X_fslope[val_idx]\n",
    "    y_tr, y_val = y_fslope[train_idx], y_fslope[val_idx]\n",
    "\n",
    "    model_fslope_cv = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    model_fslope_cv.fit(X_tr, y_tr)\n",
    "    y_val_pred = model_fslope_cv.predict(X_val)\n",
    "\n",
    "    fold_rmse = rmse(y_val, y_val_pred)\n",
    "    fold_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    rmse_scores_fslope.append(fold_rmse)\n",
    "    mae_scores_fslope.append(fold_mae)\n",
    "\n",
    "    print(f\"Fold {fold}: RMSE = {fold_rmse:.3f}, MAE = {fold_mae:.3f}\")\n",
    "\n",
    "cv_end_time = time.time()\n",
    "cv_time_fslope = cv_end_time - cv_start_time\n",
    "\n",
    "rmse_mean_fslope = np.mean(rmse_scores_fslope)\n",
    "rmse_std_fslope = np.std(rmse_scores_fslope)\n",
    "mae_mean_fslope = np.mean(mae_scores_fslope)\n",
    "mae_std_fslope = np.std(mae_scores_fslope)\n",
    "\n",
    "print(\"\\nProposed (fslope) CV results:\")\n",
    "print(f\"  RMSE mean = {rmse_mean_fslope:.3f}, std = {rmse_std_fslope:.3f}\")\n",
    "print(f\"  MAE  mean = {mae_mean_fslope:.3f}, std = {mae_std_fslope:.3f}\")\n",
    "print(f\"Proposed (fslope) CV time (5 folds): {cv_time_fslope:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7492de0-2bb0-41ea-b389-a3305d7eca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final proposed (fslope) model trained successfully.\n",
      "Training time (full fslope features): 5.511 seconds\n",
      "Number of training samples: 17731\n",
      "Number of features        : 168\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 – Final XGBoost model trained on full fslope feature set\n",
    "\n",
    "model_fslope = XGBRegressor(\n",
    "    n_estimators=400,           # slightly larger than CV (300), like your baseline final model\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train on ALL fslope-augmented training windows\n",
    "model_fslope.fit(X_fslope, y_fslope)\n",
    "\n",
    "end_time = time.time()\n",
    "fslope_train_model_time = end_time - start_time\n",
    "\n",
    "print(\"Final proposed (fslope) model trained successfully.\")\n",
    "print(f\"Training time (full fslope features): {fslope_train_model_time:.3f} seconds\")\n",
    "print(f\"Number of training samples: {X_fslope.shape[0]}\")\n",
    "print(f\"Number of features        : {X_fslope.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d4c091-4bd8-4aea-8b7d-ca6f0347f951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\4161080762.py:106: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_skew = skew(x)\n",
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\4161080762.py:107: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_kurt = kurtosis(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope) TEST feature extraction completed.\n",
      "Proposed (fslope) TEST feature extraction time: 383.331 seconds\n",
      "test_features_fslope_full shape: (10196, 171)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 – TEST feature extraction with fslope (proposed pipeline)\n",
    "\n",
    "def add_dummy_rul(test_df):\n",
    "    \"\"\"\n",
    "    Add a dummy RUL column to the test set so that the same\n",
    "    rolling feature generator can be reused.\n",
    "\n",
    "    The dummy RUL will later be replaced with the true RUL values\n",
    "    from rul_test_final for the last cycle of each engine.\n",
    "    \"\"\"\n",
    "    df = test_df.copy()\n",
    "    df[\"RUL\"] = 0  # placeholder, not used directly for test labeling\n",
    "    return df\n",
    "\n",
    "\n",
    "# Add dummy RUL to test trajectories\n",
    "test_with_dummy_rul = add_dummy_rul(test_raw)\n",
    "\n",
    "# Time the TEST feature extraction with fslope\n",
    "start_time = time.time()\n",
    "\n",
    "test_features_fslope_full = generate_rolling_features_fslope(\n",
    "    test_with_dummy_rul,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "fslope_test_time = end_time - start_time\n",
    "\n",
    "print(\"Proposed (fslope) TEST feature extraction completed.\")\n",
    "print(f\"Proposed (fslope) TEST feature extraction time: {fslope_test_time:.3f} seconds\")\n",
    "print(f\"test_features_fslope_full shape: {test_features_fslope_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08d7a5f-61fa-40e5-9c4f-e859fb182f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope) TEST evaluation:\n",
      "  test_features_fslope_last shape: (100, 171)\n",
      "  X_test_fslope shape            : (100, 168)\n",
      "  y_test_fslope shape            : (100,)\n",
      "  TEST RMSE (fslope)             : 22.350\n",
      "  TEST MAE  (fslope)             : 17.190\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 – TEST evaluation for the proposed fslope model\n",
    "\n",
    "# 1) For each test engine, keep ONLY the last available window\n",
    "idx_last_per_unit_fslope = (\n",
    "    test_features_fslope_full.groupby(\"unit_nr\")[\"time_cycles\"].idxmax()\n",
    ")\n",
    "\n",
    "test_features_fslope_last = (\n",
    "    test_features_fslope_full\n",
    "        .loc[idx_last_per_unit_fslope]\n",
    "        .sort_values(\"unit_nr\")\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) Replace dummy RUL with true final RUL from rul_test_final\n",
    "test_features_fslope_last[\"RUL\"] = rul_test_final[\"RUL\"].reset_index(drop=True)\n",
    "\n",
    "# 3) Build X_test and y_test using the SAME feature columns as training\n",
    "#    (feature_cols_fslope was defined in Cell 4/5)\n",
    "X_test_fslope = test_features_fslope_last[feature_cols_fslope].values\n",
    "y_test_fslope = test_features_fslope_last[\"RUL\"].values\n",
    "\n",
    "# 4) Predict with the final fslope model and compute metrics\n",
    "y_test_fslope_pred = model_fslope.predict(X_test_fslope)\n",
    "\n",
    "test_rmse_fslope = rmse(y_test_fslope, y_test_fslope_pred)\n",
    "test_mae_fslope  = mean_absolute_error(y_test_fslope, y_test_fslope_pred)\n",
    "\n",
    "print(\"Proposed (fslope) TEST evaluation:\")\n",
    "print(f\"  test_features_fslope_last shape: {test_features_fslope_last.shape}\")\n",
    "print(f\"  X_test_fslope shape            : {X_test_fslope.shape}\")\n",
    "print(f\"  y_test_fslope shape            : {y_test_fslope.shape}\")\n",
    "print(f\"  TEST RMSE (fslope)             : {test_rmse_fslope:.3f}\")\n",
    "print(f\"  TEST MAE  (fslope)             : {test_mae_fslope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac700f0-507a-4eff-a069-78b764254af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF-ER helpers and rolling feature generators (LFER-only) are defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 – LF-ER (low-frequency energy ratio) feature extraction\n",
    "\n",
    "def compute_lfer(x_window, low_freq_ratio=0.25, epsilon=EPSILON):\n",
    "    \"\"\"\n",
    "    Compute the low-frequency energy ratio (LF-ER) for a 1D window.\n",
    "\n",
    "    Steps:\n",
    "      1) Compute FFT of the windowed signal using rfft (real FFT).\n",
    "      2) Compute spectral energy |X(f)|^2 for each frequency bin.\n",
    "      3) Define a low-frequency band as the first K non-DC bins:\n",
    "            K = max(1, floor(low_freq_ratio * (N_bins - 1)))\n",
    "         where N_bins = len(power_spectrum).\n",
    "      4) LF-ER = (sum of low-frequency energy) / (total energy + epsilon).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_window : array-like, shape (w,)\n",
    "        Values of a single sensor/setting in the current window.\n",
    "    low_freq_ratio : float\n",
    "        Fraction of non-DC FFT bins to treat as \"low frequency\" (0 < ratio <= 1).\n",
    "    epsilon : float\n",
    "        Small constant to avoid division by zero.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lfer : float\n",
    "        Low-frequency energy ratio for this window.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x_window, dtype=np.float64)\n",
    "\n",
    "    # Optionally, we could remove the mean to focus on oscillatory behavior.\n",
    "    # Here we follow a simple, consistent approach:\n",
    "    X = rfft(x)\n",
    "    power = np.abs(X) ** 2\n",
    "\n",
    "    total_energy = power.sum()\n",
    "\n",
    "    if len(power) <= 1:\n",
    "        # Degenerate FFT (e.g., constant or extremely short signal)\n",
    "        return 0.0\n",
    "\n",
    "    # Exclude DC (index 0) when defining low-frequency band\n",
    "    n_non_dc = len(power) - 1\n",
    "    k_low = int(np.floor(low_freq_ratio * n_non_dc))\n",
    "    k_low = max(1, k_low)  # at least 1 low-frequency bin\n",
    "\n",
    "    # Low-frequency bins: indices 1 .. k_low (inclusive)\n",
    "    low_energy = power[1 : 1 + k_low].sum()\n",
    "\n",
    "    lfer = low_energy / (total_energy + epsilon)\n",
    "    return float(lfer)\n",
    "\n",
    "\n",
    "def generate_rolling_features_for_unit_lfer(\n",
    "    df_unit,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,\n",
    "    epsilon=EPSILON,\n",
    "):\n",
    "    \"\"\"\n",
    "    Per-unit rolling feature generator with baseline stats + LF-ER.\n",
    "\n",
    "    For a single engine (unit_nr), this function:\n",
    "      - sorts by time_cycles,\n",
    "      - uses a sliding window of length `window` and step `stride`,\n",
    "      - for EACH variable in SENSOR_COLS + SETTING_COLS:\n",
    "          * computes baseline statistics:\n",
    "                mean, std, min, max, skew, kurtosis\n",
    "          * additionally computes LF-ER (low-frequency energy ratio),\n",
    "      - labels each window with the RUL at the last cycle in the window,\n",
    "      - records unit_nr and time_cycles of the last cycle.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_df : pd.DataFrame\n",
    "        One row per window, with columns:\n",
    "          - 'unit_nr', 'time_cycles'\n",
    "          - baseline stats for each variable\n",
    "          - '{var}_lfer' for each variable\n",
    "          - 'RUL' (label at last cycle in window)\n",
    "    \"\"\"\n",
    "    df_unit = df_unit.sort_values(\"time_cycles\").reset_index(drop=True)\n",
    "    n_cycles = len(df_unit)\n",
    "\n",
    "    if n_cycles < window:\n",
    "        # Not enough cycles to form a single window\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    var_cols = SENSOR_COLS + SETTING_COLS\n",
    "\n",
    "    for start in range(0, n_cycles - window + 1, stride):\n",
    "        end = start + window\n",
    "        window_df = df_unit.iloc[start:end]\n",
    "\n",
    "        last_row = window_df.iloc[-1]\n",
    "        row_dict = {\n",
    "            \"unit_nr\": last_row[\"unit_nr\"],\n",
    "            \"time_cycles\": last_row[\"time_cycles\"],\n",
    "        }\n",
    "\n",
    "        # Compute features for each variable in the window\n",
    "        for col in var_cols:\n",
    "            x = window_df[col].values.astype(np.float64)\n",
    "\n",
    "            # Baseline rolling stats\n",
    "            x_mean = x.mean()\n",
    "            x_std = x.std(ddof=0)\n",
    "            x_min = x.min()\n",
    "            x_max = x.max()\n",
    "            x_skew = skew(x)\n",
    "            x_kurt = kurtosis(x)\n",
    "\n",
    "            row_dict[f\"{col}_mean\"] = x_mean\n",
    "            row_dict[f\"{col}_std\"] = x_std\n",
    "            row_dict[f\"{col}_min\"] = x_min\n",
    "            row_dict[f\"{col}_max\"] = x_max\n",
    "            row_dict[f\"{col}_skew\"] = x_skew\n",
    "            row_dict[f\"{col}_kurt\"] = x_kurt\n",
    "\n",
    "            # New LF-ER feature\n",
    "            row_dict[f\"{col}_lfer\"] = compute_lfer(\n",
    "                x_window=x,\n",
    "                low_freq_ratio=low_freq_ratio,\n",
    "                epsilon=epsilon,\n",
    "            )\n",
    "\n",
    "        # RUL label taken at the last cycle in the window\n",
    "        row_dict[\"RUL\"] = last_row[\"RUL\"]\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "    features_df = pd.DataFrame(rows)\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def generate_rolling_features_lfer(\n",
    "    df,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,\n",
    "    epsilon=EPSILON,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper over generate_rolling_features_for_unit_lfer for all engines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Full labeled dataset (e.g., train_labeled or test_with_dummy_rul),\n",
    "        containing 'unit_nr', 'time_cycles', 'RUL', SENSOR_COLS, SETTING_COLS.\n",
    "    window : int\n",
    "        Sliding window length (same as baseline).\n",
    "    stride : int\n",
    "        Sliding window step (same as baseline).\n",
    "    low_freq_ratio : float\n",
    "        Fraction of FFT non-DC bins treated as low frequency.\n",
    "    epsilon : float\n",
    "        Small constant for LF-ER normalization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_all : pd.DataFrame\n",
    "        Concatenation of per-unit features, sorted by unit_nr and time_cycles.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "\n",
    "    for unit_id, df_unit in df.groupby(\"unit_nr\"):\n",
    "        feats_unit = generate_rolling_features_for_unit_lfer(\n",
    "            df_unit,\n",
    "            window=window,\n",
    "            stride=stride,\n",
    "            low_freq_ratio=low_freq_ratio,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "        if not feats_unit.empty:\n",
    "            all_features.append(feats_unit)\n",
    "\n",
    "    if not all_features:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    features_all = pd.concat(all_features, axis=0, ignore_index=True)\n",
    "    features_all = features_all.sort_values([\"unit_nr\", \"time_cycles\"]).reset_index(drop=True)\n",
    "    return features_all\n",
    "\n",
    "\n",
    "print(\"LF-ER helpers and rolling feature generators (LFER-only) are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf62030-4511-4c75-ac7e-58f1f310849b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\120442753.py:112: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_skew = skew(x)\n",
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\120442753.py:113: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_kurt = kurtosis(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (LF-ER) TRAIN feature extraction completed.\n",
      "Proposed (LF-ER) TRAIN feature extraction time: 691.601 seconds\n",
      "train_features_lfer shape: (17731, 171)\n",
      "Number of features (proposed LF-ER): 168\n",
      "Example feature columns (first 15):\n",
      "['s_1_mean', 's_1_std', 's_1_min', 's_1_max', 's_1_skew', 's_1_kurt', 's_1_lfer', 's_2_mean', 's_2_std', 's_2_min', 's_2_max', 's_2_skew', 's_2_kurt', 's_2_lfer', 's_3_mean']\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 – Train feature extraction with LF-ER (proposed LF-ER-only pipeline)\n",
    "\n",
    "# Generate sliding-window features with baseline stats + LF-ER\n",
    "start_time = time.time()\n",
    "\n",
    "train_features_lfer = generate_rolling_features_lfer(\n",
    "    train_labeled,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,  # first 25% of non-DC FFT bins as \"low frequency\"\n",
    "    epsilon=EPSILON,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "lfer_train_time = end_time - start_time\n",
    "\n",
    "print(\"Proposed (LF-ER) TRAIN feature extraction completed.\")\n",
    "print(f\"Proposed (LF-ER) TRAIN feature extraction time: {lfer_train_time:.3f} seconds\")\n",
    "print(f\"train_features_lfer shape: {train_features_lfer.shape}\")\n",
    "\n",
    "# Inspect feature columns (exclude ID/label columns)\n",
    "non_feature_cols_lfer = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "feature_cols_lfer = [c for c in train_features_lfer.columns if c not in non_feature_cols_lfer]\n",
    "\n",
    "print(f\"Number of features (proposed LF-ER): {len(feature_cols_lfer)}\")\n",
    "print(\"Example feature columns (first 15):\")\n",
    "print(feature_cols_lfer[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4513e9b6-bf2b-4817-a71a-057a0a1611d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (LF-ER) design matrix constructed.\n",
      "X_lfer shape      : (17731, 168)\n",
      "y_lfer shape      : (17731,)\n",
      "groups_lfer shape : (17731,)\n",
      "Number of features (LF-ER): 168\n",
      "Example feature columns (first 15):\n",
      "['s_1_mean', 's_1_std', 's_1_min', 's_1_max', 's_1_skew', 's_1_kurt', 's_1_lfer', 's_2_mean', 's_2_std', 's_2_min', 's_2_max', 's_2_skew', 's_2_kurt', 's_2_lfer', 's_3_mean']\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 – Build X, y, groups for the LF-ER-augmented pipeline\n",
    "\n",
    "# Non-feature columns: identifiers and label\n",
    "non_feature_cols_lfer = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "\n",
    "# Rebuild feature_cols_lfer defensively (in case of re-runs)\n",
    "feature_cols_lfer = [\n",
    "    c for c in train_features_lfer.columns\n",
    "    if c not in non_feature_cols_lfer\n",
    "]\n",
    "\n",
    "# Design matrix (features), target (RUL), and groups (unit_nr)\n",
    "X_lfer = train_features_lfer[feature_cols_lfer].values\n",
    "y_lfer = train_features_lfer[\"RUL\"].values\n",
    "groups_lfer = train_features_lfer[\"unit_nr\"].values\n",
    "\n",
    "print(\"Proposed (LF-ER) design matrix constructed.\")\n",
    "print(f\"X_lfer shape      : {X_lfer.shape}\")\n",
    "print(f\"y_lfer shape      : {y_lfer.shape}\")\n",
    "print(f\"groups_lfer shape : {groups_lfer.shape}\")\n",
    "print(f\"Number of features (LF-ER): {len(feature_cols_lfer)}\")\n",
    "print(\"Example feature columns (first 15):\")\n",
    "print(feature_cols_lfer[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "658cc08e-11ab-40a8-a7a7-812ba8c4463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE = 43.135, MAE = 27.614\n",
      "Fold 2: RMSE = 37.270, MAE = 24.917\n",
      "Fold 3: RMSE = 35.514, MAE = 23.420\n",
      "Fold 4: RMSE = 38.462, MAE = 26.377\n",
      "Fold 5: RMSE = 33.803, MAE = 23.605\n",
      "\n",
      "Proposed (LF-ER) CV results:\n",
      "  RMSE mean = 37.637, std = 3.170\n",
      "  MAE  mean = 25.187, std = 1.613\n",
      "Proposed (LF-ER) CV time (5 folds): 16.657 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 – GroupKFold CV with XGBoost (proposed LF-ER features)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "gkf_lfer = GroupKFold(n_splits=5)\n",
    "\n",
    "rmse_scores_lfer = []\n",
    "mae_scores_lfer = []\n",
    "\n",
    "cv_start_time_lfer = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    gkf_lfer.split(X_lfer, y_lfer, groups_lfer), start=1\n",
    "):\n",
    "    X_tr, X_val = X_lfer[train_idx], X_lfer[val_idx]\n",
    "    y_tr, y_val = y_lfer[train_idx], y_lfer[val_idx]\n",
    "\n",
    "    model_lfer_cv = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    model_lfer_cv.fit(X_tr, y_tr)\n",
    "    y_val_pred = model_lfer_cv.predict(X_val)\n",
    "\n",
    "    fold_rmse = rmse(y_val, y_val_pred)\n",
    "    fold_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    rmse_scores_lfer.append(fold_rmse)\n",
    "    mae_scores_lfer.append(fold_mae)\n",
    "\n",
    "    print(f\"Fold {fold}: RMSE = {fold_rmse:.3f}, MAE = {fold_mae:.3f}\")\n",
    "\n",
    "cv_end_time_lfer = time.time()\n",
    "cv_time_lfer = cv_end_time_lfer - cv_start_time_lfer\n",
    "\n",
    "rmse_mean_lfer = np.mean(rmse_scores_lfer)\n",
    "rmse_std_lfer = np.std(rmse_scores_lfer)\n",
    "mae_mean_lfer = np.mean(mae_scores_lfer)\n",
    "mae_std_lfer = np.std(mae_scores_lfer)\n",
    "\n",
    "print(\"\\nProposed (LF-ER) CV results:\")\n",
    "print(f\"  RMSE mean = {rmse_mean_lfer:.3f}, std = {rmse_std_lfer:.3f}\")\n",
    "print(f\"  MAE  mean = {mae_mean_lfer:.3f}, std = {mae_std_lfer:.3f}\")\n",
    "print(f\"Proposed (LF-ER) CV time (5 folds): {cv_time_lfer:.3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3ea1cc-992f-4728-93d4-5e42c1726c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final proposed (LF-ER) model trained successfully.\n",
      "Training time (full LF-ER features): 5.074 seconds\n",
      "Number of training samples: 17731\n",
      "Number of features        : 168\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 – Final XGBoost model trained on full LF-ER feature set\n",
    "\n",
    "model_lfer = XGBRegressor(\n",
    "    n_estimators=400,           # match final models: a bit larger than CV\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train on ALL LF-ER-augmented training windows\n",
    "model_lfer.fit(X_lfer, y_lfer)\n",
    "\n",
    "end_time = time.time()\n",
    "lfer_train_model_time = end_time - start_time\n",
    "\n",
    "print(\"Final proposed (LF-ER) model trained successfully.\")\n",
    "print(f\"Training time (full LF-ER features): {lfer_train_model_time:.3f} seconds\")\n",
    "print(f\"Number of training samples: {X_lfer.shape[0]}\")\n",
    "print(f\"Number of features        : {X_lfer.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d29c602-abf2-44e6-8a22-15fc43a35056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\120442753.py:112: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_skew = skew(x)\n",
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\120442753.py:113: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_kurt = kurtosis(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (LF-ER) TEST feature extraction completed.\n",
      "Proposed (LF-ER) TEST feature extraction time: 395.505 seconds\n",
      "test_features_lfer_full shape: (10196, 171)\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 – TEST feature extraction with LF-ER (proposed LF-ER-only pipeline)\n",
    "\n",
    "# Ensure we have a test DataFrame with a dummy RUL column (reused from fslope part)\n",
    "def add_dummy_rul(test_df):\n",
    "    \"\"\"\n",
    "    Add a dummy RUL column to the test set so that the same\n",
    "    rolling feature generator can be reused.\n",
    "\n",
    "    The dummy RUL will later be replaced with the true RUL values\n",
    "    from rul_test_final for the last cycle of each engine.\n",
    "    \"\"\"\n",
    "    df = test_df.copy()\n",
    "    df[\"RUL\"] = 0  # placeholder, not used directly for test labeling\n",
    "    return df\n",
    "\n",
    "\n",
    "# If test_with_dummy_rul was already created for fslope, reuse it; otherwise create it.\n",
    "if \"test_with_dummy_rul\" not in globals():\n",
    "    test_with_dummy_rul = add_dummy_rul(test_raw)\n",
    "\n",
    "# Time the TEST feature extraction with LF-ER\n",
    "start_time = time.time()\n",
    "\n",
    "test_features_lfer_full = generate_rolling_features_lfer(\n",
    "    test_with_dummy_rul,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,\n",
    "    epsilon=EPSILON,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "lfer_test_time = end_time - start_time\n",
    "\n",
    "print(\"Proposed (LF-ER) TEST feature extraction completed.\")\n",
    "print(f\"Proposed (LF-ER) TEST feature extraction time: {lfer_test_time:.3f} seconds\")\n",
    "print(f\"test_features_lfer_full shape: {test_features_lfer_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4a3c08d-0b9c-4aea-b42c-704925e37035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (LF-ER) TEST evaluation:\n",
      "  test_features_lfer_last shape: (100, 171)\n",
      "  X_test_lfer shape            : (100, 168)\n",
      "  y_test_lfer shape            : (100,)\n",
      "  TEST RMSE (LF-ER)            : 27.920\n",
      "  TEST MAE  (LF-ER)            : 20.035\n"
     ]
    }
   ],
   "source": [
    "# Cell 16 – TEST evaluation for the proposed LF-ER model\n",
    "\n",
    "# 1) For each test engine, keep ONLY the last available window\n",
    "idx_last_per_unit_lfer = (\n",
    "    test_features_lfer_full.groupby(\"unit_nr\")[\"time_cycles\"].idxmax()\n",
    ")\n",
    "\n",
    "test_features_lfer_last = (\n",
    "    test_features_lfer_full\n",
    "        .loc[idx_last_per_unit_lfer]\n",
    "        .sort_values(\"unit_nr\")\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) Replace dummy RUL with true final RUL from rul_test_final\n",
    "test_features_lfer_last[\"RUL\"] = rul_test_final[\"RUL\"].reset_index(drop=True)\n",
    "\n",
    "# 3) Build X_test and y_test using the SAME feature columns as training\n",
    "X_test_lfer = test_features_lfer_last[feature_cols_lfer].values\n",
    "y_test_lfer = test_features_lfer_last[\"RUL\"].values\n",
    "\n",
    "# 4) Predict with the final LF-ER model and compute metrics\n",
    "y_test_lfer_pred = model_lfer.predict(X_test_lfer)\n",
    "\n",
    "test_rmse_lfer = rmse(y_test_lfer, y_test_lfer_pred)\n",
    "test_mae_lfer  = mean_absolute_error(y_test_lfer, y_test_lfer_pred)\n",
    "\n",
    "print(\"Proposed (LF-ER) TEST evaluation:\")\n",
    "print(f\"  test_features_lfer_last shape: {test_features_lfer_last.shape}\")\n",
    "print(f\"  X_test_lfer shape            : {X_test_lfer.shape}\")\n",
    "print(f\"  y_test_lfer shape            : {y_test_lfer.shape}\")\n",
    "print(f\"  TEST RMSE (LF-ER)            : {test_rmse_lfer:.3f}\")\n",
    "print(f\"  TEST MAE  (LF-ER)            : {test_mae_lfer:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5efff9c-1e59-41ef-a8a1-cea14a648ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined fslope + LF-ER rolling feature generators are defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 17 – Combined rolling features: baseline stats + fslope + LF-ER\n",
    "\n",
    "def generate_rolling_features_for_unit_fslope_lfer(\n",
    "    df_unit,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,\n",
    "    epsilon=EPSILON,\n",
    "):\n",
    "    \"\"\"\n",
    "    Per-unit rolling feature generator with:\n",
    "      - baseline statistics,\n",
    "      - fslope (normalized trend slope),\n",
    "      - LF-ER (low-frequency energy ratio).\n",
    "\n",
    "    For a single engine (unit_nr), this function:\n",
    "      - sorts by time_cycles,\n",
    "      - uses a sliding window of length `window` and step `stride`,\n",
    "      - for EACH variable in SENSOR_COLS + SETTING_COLS:\n",
    "          * baseline stats:\n",
    "                mean, std, min, max, skew, kurtosis\n",
    "          * fslope:\n",
    "                normalized linear trend slope over the window\n",
    "          * lfer:\n",
    "                low-frequency energy ratio from FFT\n",
    "      - labels each window with the RUL at the last cycle in the window,\n",
    "      - records unit_nr and time_cycles of the last cycle.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_df : pd.DataFrame\n",
    "        One row per window, with columns:\n",
    "          - 'unit_nr', 'time_cycles'\n",
    "          - '{var}_mean', '{var}_std', '{var}_min', '{var}_max',\n",
    "            '{var}_skew', '{var}_kurt'\n",
    "          - '{var}_fslope'\n",
    "          - '{var}_lfer'\n",
    "          - 'RUL'\n",
    "    \"\"\"\n",
    "    df_unit = df_unit.sort_values(\"time_cycles\").reset_index(drop=True)\n",
    "    n_cycles = len(df_unit)\n",
    "\n",
    "    if n_cycles < window:\n",
    "        # Not enough cycles to form a single window\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    var_cols = SENSOR_COLS + SETTING_COLS\n",
    "\n",
    "    # Precompute time indices for fslope regression (0, 1, ..., window-1)\n",
    "    t_idx = np.arange(window, dtype=np.float64)\n",
    "    t_mean = t_idx.mean()\n",
    "    denom_t = np.sum((t_idx - t_mean) ** 2)\n",
    "\n",
    "    for start in range(0, n_cycles - window + 1, stride):\n",
    "        end = start + window\n",
    "        window_df = df_unit.iloc[start:end]\n",
    "\n",
    "        last_row = window_df.iloc[-1]\n",
    "        row_dict = {\n",
    "            \"unit_nr\": last_row[\"unit_nr\"],\n",
    "            \"time_cycles\": last_row[\"time_cycles\"],\n",
    "        }\n",
    "\n",
    "        for col in var_cols:\n",
    "            x = window_df[col].values.astype(np.float64)\n",
    "\n",
    "            # ---- Baseline rolling stats ----\n",
    "            x_mean = x.mean()\n",
    "            x_std = x.std(ddof=0)\n",
    "            x_min = x.min()\n",
    "            x_max = x.max()\n",
    "            x_skew = skew(x)\n",
    "            x_kurt = kurtosis(x)\n",
    "\n",
    "            row_dict[f\"{col}_mean\"] = x_mean\n",
    "            row_dict[f\"{col}_std\"] = x_std\n",
    "            row_dict[f\"{col}_min\"] = x_min\n",
    "            row_dict[f\"{col}_max\"] = x_max\n",
    "            row_dict[f\"{col}_skew\"] = x_skew\n",
    "            row_dict[f\"{col}_kurt\"] = x_kurt\n",
    "\n",
    "            # ---- fslope feature ----\n",
    "            row_dict[f\"{col}_fslope\"] = compute_fslope(\n",
    "                x_window=x,\n",
    "                t_idx=t_idx,\n",
    "                t_mean=t_mean,\n",
    "                denom_t=denom_t,\n",
    "                epsilon=epsilon,\n",
    "            )\n",
    "\n",
    "            # ---- LF-ER feature ----\n",
    "            row_dict[f\"{col}_lfer\"] = compute_lfer(\n",
    "                x_window=x,\n",
    "                low_freq_ratio=low_freq_ratio,\n",
    "                epsilon=epsilon,\n",
    "            )\n",
    "\n",
    "        # Label (RUL at last cycle in the window)\n",
    "        row_dict[\"RUL\"] = last_row[\"RUL\"]\n",
    "\n",
    "        rows.append(row_dict)\n",
    "\n",
    "    features_df = pd.DataFrame(rows)\n",
    "    return features_df\n",
    "\n",
    "\n",
    "def generate_rolling_features_fslope_lfer(\n",
    "    df,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,\n",
    "    epsilon=EPSILON,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper over generate_rolling_features_for_unit_fslope_lfer for all engines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Full labeled dataset (train_labeled or test_with_dummy_rul),\n",
    "        containing 'unit_nr', 'time_cycles', 'RUL', SENSOR_COLS, SETTING_COLS.\n",
    "    window : int\n",
    "        Sliding window length.\n",
    "    stride : int\n",
    "        Sliding window step.\n",
    "    low_freq_ratio : float\n",
    "        Fraction of non-DC FFT bins treated as \"low frequency\".\n",
    "    epsilon : float\n",
    "        Small constant for numerical stability.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_all : pd.DataFrame\n",
    "        Concatenation of per-unit features, sorted by unit_nr and time_cycles.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "\n",
    "    for unit_id, df_unit in df.groupby(\"unit_nr\"):\n",
    "        feats_unit = generate_rolling_features_for_unit_fslope_lfer(\n",
    "            df_unit,\n",
    "            window=window,\n",
    "            stride=stride,\n",
    "            low_freq_ratio=low_freq_ratio,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "        if not feats_unit.empty:\n",
    "            all_features.append(feats_unit)\n",
    "\n",
    "    if not all_features:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    features_all = pd.concat(all_features, axis=0, ignore_index=True)\n",
    "    features_all = features_all.sort_values([\"unit_nr\", \"time_cycles\"]).reset_index(drop=True)\n",
    "    return features_all\n",
    "\n",
    "\n",
    "print(\"Combined fslope + LF-ER rolling feature generators are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab8db605-5341-4681-a35c-d1bfc17856da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\1908113684.py:73: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_skew = skew(x)\n",
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\1908113684.py:74: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_kurt = kurtosis(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope + LF-ER) TRAIN feature extraction completed.\n",
      "Proposed (fslope + LF-ER) TRAIN feature extraction time: 809.753 seconds\n",
      "train_features_fslope_lfer shape: (17731, 195)\n",
      "Number of features (fslope + LF-ER): 192\n",
      "Example feature columns (first 20):\n",
      "['s_1_mean', 's_1_std', 's_1_min', 's_1_max', 's_1_skew', 's_1_kurt', 's_1_fslope', 's_1_lfer', 's_2_mean', 's_2_std', 's_2_min', 's_2_max', 's_2_skew', 's_2_kurt', 's_2_fslope', 's_2_lfer', 's_3_mean', 's_3_std', 's_3_min', 's_3_max']\n"
     ]
    }
   ],
   "source": [
    "# Cell 18 – Train feature extraction with combined fslope + LF-ER features\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate sliding-window features with:\n",
    "#   baseline stats + fslope + LF-ER\n",
    "train_features_fslope_lfer = generate_rolling_features_fslope_lfer(\n",
    "    train_labeled,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,  # same LF band definition as before\n",
    "    epsilon=EPSILON,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "fslope_lfer_train_time = end_time - start_time\n",
    "\n",
    "print(\"Proposed (fslope + LF-ER) TRAIN feature extraction completed.\")\n",
    "print(f\"Proposed (fslope + LF-ER) TRAIN feature extraction time: {fslope_lfer_train_time:.3f} seconds\")\n",
    "print(f\"train_features_fslope_lfer shape: {train_features_fslope_lfer.shape}\")\n",
    "\n",
    "# Identify feature columns (exclude ID/label columns)\n",
    "non_feature_cols_fslope_lfer = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "feature_cols_fslope_lfer = [\n",
    "    c for c in train_features_fslope_lfer.columns\n",
    "    if c not in non_feature_cols_fslope_lfer\n",
    "]\n",
    "\n",
    "print(f\"Number of features (fslope + LF-ER): {len(feature_cols_fslope_lfer)}\")\n",
    "print(\"Example feature columns (first 20):\")\n",
    "print(feature_cols_fslope_lfer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1625472d-e2ac-450e-858d-502c81dd5ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope + LF-ER) design matrix constructed.\n",
      "X_fslope_lfer shape      : (17731, 192)\n",
      "y_fslope_lfer shape      : (17731,)\n",
      "groups_fslope_lfer shape : (17731,)\n",
      "Number of features (fslope + LF-ER): 192\n",
      "Example feature columns (first 20):\n",
      "['s_1_mean', 's_1_std', 's_1_min', 's_1_max', 's_1_skew', 's_1_kurt', 's_1_fslope', 's_1_lfer', 's_2_mean', 's_2_std', 's_2_min', 's_2_max', 's_2_skew', 's_2_kurt', 's_2_fslope', 's_2_lfer', 's_3_mean', 's_3_std', 's_3_min', 's_3_max']\n"
     ]
    }
   ],
   "source": [
    "# Cell 19 – Build X, y, groups for the combined fslope + LF-ER pipeline\n",
    "\n",
    "# Non-feature columns: identifiers and label\n",
    "non_feature_cols_fslope_lfer = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "\n",
    "# Rebuild feature_cols_fslope_lfer defensively (in case cells are re-run out of order)\n",
    "feature_cols_fslope_lfer = [\n",
    "    c for c in train_features_fslope_lfer.columns\n",
    "    if c not in non_feature_cols_fslope_lfer\n",
    "]\n",
    "\n",
    "# Design matrix (features), target (RUL), and groups (unit_nr)\n",
    "X_fslope_lfer = train_features_fslope_lfer[feature_cols_fslope_lfer].values\n",
    "y_fslope_lfer = train_features_fslope_lfer[\"RUL\"].values\n",
    "groups_fslope_lfer = train_features_fslope_lfer[\"unit_nr\"].values\n",
    "\n",
    "print(\"Proposed (fslope + LF-ER) design matrix constructed.\")\n",
    "print(f\"X_fslope_lfer shape      : {X_fslope_lfer.shape}\")\n",
    "print(f\"y_fslope_lfer shape      : {y_fslope_lfer.shape}\")\n",
    "print(f\"groups_fslope_lfer shape : {groups_fslope_lfer.shape}\")\n",
    "print(f\"Number of features (fslope + LF-ER): {len(feature_cols_fslope_lfer)}\")\n",
    "print(\"Example feature columns (first 20):\")\n",
    "print(feature_cols_fslope_lfer[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a687667b-98ed-49d6-a360-2bf463858b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE = 38.486, MAE = 23.791\n",
      "Fold 2: RMSE = 32.607, MAE = 20.742\n",
      "Fold 3: RMSE = 31.632, MAE = 20.434\n",
      "Fold 4: RMSE = 33.243, MAE = 22.333\n",
      "Fold 5: RMSE = 29.480, MAE = 20.574\n",
      "\n",
      "Proposed (fslope + LF-ER) CV results:\n",
      "  RMSE mean = 33.090, std = 2.984\n",
      "  MAE  mean = 21.575, std = 1.303\n",
      "Proposed (fslope + LF-ER) CV time (5 folds): 20.373 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 20 – GroupKFold CV with XGBoost (combined fslope + LF-ER features)\n",
    "\n",
    "# Reuse rmse() from earlier; if not defined (e.g., cells run out of order), define it here.\n",
    "try:\n",
    "    rmse\n",
    "except NameError:\n",
    "    def rmse(y_true, y_pred):\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "gkf_fslope_lfer = GroupKFold(n_splits=5)\n",
    "\n",
    "rmse_scores_fslope_lfer = []\n",
    "mae_scores_fslope_lfer = []\n",
    "\n",
    "cv_start_time_fslope_lfer = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(\n",
    "    gkf_fslope_lfer.split(X_fslope_lfer, y_fslope_lfer, groups_fslope_lfer),\n",
    "    start=1\n",
    "):\n",
    "    X_tr, X_val = X_fslope_lfer[train_idx], X_fslope_lfer[val_idx]\n",
    "    y_tr, y_val = y_fslope_lfer[train_idx], y_fslope_lfer[val_idx]\n",
    "\n",
    "    model_fslope_lfer_cv = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    model_fslope_lfer_cv.fit(X_tr, y_tr)\n",
    "    y_val_pred = model_fslope_lfer_cv.predict(X_val)\n",
    "\n",
    "    fold_rmse = rmse(y_val, y_val_pred)\n",
    "    fold_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    rmse_scores_fslope_lfer.append(fold_rmse)\n",
    "    mae_scores_fslope_lfer.append(fold_mae)\n",
    "\n",
    "    print(f\"Fold {fold}: RMSE = {fold_rmse:.3f}, MAE = {fold_mae:.3f}\")\n",
    "\n",
    "cv_end_time_fslope_lfer = time.time()\n",
    "cv_time_fslope_lfer = cv_end_time_fslope_lfer - cv_start_time_fslope_lfer\n",
    "\n",
    "rmse_mean_fslope_lfer = np.mean(rmse_scores_fslope_lfer)\n",
    "rmse_std_fslope_lfer = np.std(rmse_scores_fslope_lfer)\n",
    "mae_mean_fslope_lfer = np.mean(mae_scores_fslope_lfer)\n",
    "mae_std_fslope_lfer = np.std(mae_scores_fslope_lfer)\n",
    "\n",
    "print(\"\\nProposed (fslope + LF-ER) CV results:\")\n",
    "print(f\"  RMSE mean = {rmse_mean_fslope_lfer:.3f}, std = {rmse_std_fslope_lfer:.3f}\")\n",
    "print(f\"  MAE  mean = {mae_mean_fslope_lfer:.3f}, std = {mae_std_fslope_lfer:.3f}\")\n",
    "print(f\"Proposed (fslope + LF-ER) CV time (5 folds): {cv_time_fslope_lfer:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8409e93-c927-4ede-9494-f18592eada43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final proposed (fslope + LF-ER) model trained successfully.\n",
      "Training time (full fslope + LF-ER features): 5.908 seconds\n",
      "Number of training samples: 17731\n",
      "Number of features        : 192\n"
     ]
    }
   ],
   "source": [
    "# Cell 21 – Final XGBoost model trained on full fslope + LF-ER feature set\n",
    "\n",
    "model_fslope_lfer = XGBRegressor(\n",
    "    n_estimators=400,           # like other final models\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train on ALL combined-feature windows\n",
    "model_fslope_lfer.fit(X_fslope_lfer, y_fslope_lfer)\n",
    "\n",
    "end_time = time.time()\n",
    "fslope_lfer_train_model_time = end_time - start_time\n",
    "\n",
    "print(\"Final proposed (fslope + LF-ER) model trained successfully.\")\n",
    "print(f\"Training time (full fslope + LF-ER features): {fslope_lfer_train_model_time:.3f} seconds\")\n",
    "print(f\"Number of training samples: {X_fslope_lfer.shape[0]}\")\n",
    "print(f\"Number of features        : {X_fslope_lfer.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e2b338-a825-42dc-b774-1568380fa523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\1908113684.py:73: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_skew = skew(x)\n",
      "C:\\Users\\hrast\\AppData\\Local\\Temp\\ipykernel_26660\\1908113684.py:74: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  x_kurt = kurtosis(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope + LF-ER) TEST feature extraction completed.\n",
      "Proposed (fslope + LF-ER) TEST feature extraction time: 451.989 seconds\n",
      "test_features_fslope_lfer_full shape: (10196, 195)\n"
     ]
    }
   ],
   "source": [
    "# Cell 22 – TEST feature extraction with combined fslope + LF-ER features\n",
    "\n",
    "# Ensure we have a test DataFrame with a dummy RUL column\n",
    "def add_dummy_rul(test_df):\n",
    "    \"\"\"\n",
    "    Add a dummy RUL column to the test set so that the same\n",
    "    rolling feature generator can be reused.\n",
    "\n",
    "    The dummy RUL will later be replaced with the true RUL values\n",
    "    from rul_test_final for the last cycle of each engine.\n",
    "    \"\"\"\n",
    "    df = test_df.copy()\n",
    "    df[\"RUL\"] = 0  # placeholder, not used directly for test labeling\n",
    "    return df\n",
    "\n",
    "\n",
    "# If test_with_dummy_rul already exists (from fslope/LF-ER), reuse it; otherwise create it.\n",
    "if \"test_with_dummy_rul\" not in globals():\n",
    "    test_with_dummy_rul = add_dummy_rul(test_raw)\n",
    "\n",
    "# Time the TEST feature extraction with combined fslope + LF-ER\n",
    "start_time = time.time()\n",
    "\n",
    "test_features_fslope_lfer_full = generate_rolling_features_fslope_lfer(\n",
    "    test_with_dummy_rul,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    low_freq_ratio=0.25,\n",
    "    epsilon=EPSILON,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "fslope_lfer_test_time = end_time - start_time\n",
    "\n",
    "print(\"Proposed (fslope + LF-ER) TEST feature extraction completed.\")\n",
    "print(f\"Proposed (fslope + LF-ER) TEST feature extraction time: {fslope_lfer_test_time:.3f} seconds\")\n",
    "print(f\"test_features_fslope_lfer_full shape: {test_features_fslope_lfer_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67236ac2-860d-4f4c-958a-8cc198b76116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed (fslope + LF-ER) TEST evaluation:\n",
      "  test_features_fslope_lfer_last shape: (100, 195)\n",
      "  X_test_fslope_lfer shape            : (100, 192)\n",
      "  y_test_fslope_lfer shape            : (100,)\n",
      "  TEST RMSE (fslope + LF-ER)          : 23.241\n",
      "  TEST MAE  (fslope + LF-ER)          : 17.623\n"
     ]
    }
   ],
   "source": [
    "# Cell 23 – TEST evaluation for the combined fslope + LF-ER model\n",
    "\n",
    "# 1) For each test engine, keep ONLY the last available window\n",
    "idx_last_per_unit_fslope_lfer = (\n",
    "    test_features_fslope_lfer_full.groupby(\"unit_nr\")[\"time_cycles\"].idxmax()\n",
    ")\n",
    "\n",
    "test_features_fslope_lfer_last = (\n",
    "    test_features_fslope_lfer_full\n",
    "        .loc[idx_last_per_unit_fslope_lfer]\n",
    "        .sort_values(\"unit_nr\")\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 2) Replace dummy RUL with true final RUL from rul_test_final\n",
    "test_features_fslope_lfer_last[\"RUL\"] = rul_test_final[\"RUL\"].reset_index(drop=True)\n",
    "\n",
    "# 3) Build X_test and y_test using the SAME feature columns as training\n",
    "X_test_fslope_lfer = test_features_fslope_lfer_last[feature_cols_fslope_lfer].values\n",
    "y_test_fslope_lfer = test_features_fslope_lfer_last[\"RUL\"].values\n",
    "\n",
    "# 4) Predict with the final combined model and compute metrics\n",
    "y_test_fslope_lfer_pred = model_fslope_lfer.predict(X_test_fslope_lfer)\n",
    "\n",
    "test_rmse_fslope_lfer = rmse(y_test_fslope_lfer, y_test_fslope_lfer_pred)\n",
    "test_mae_fslope_lfer  = mean_absolute_error(y_test_fslope_lfer, y_test_fslope_lfer_pred)\n",
    "\n",
    "print(\"Proposed (fslope + LF-ER) TEST evaluation:\")\n",
    "print(f\"  test_features_fslope_lfer_last shape: {test_features_fslope_lfer_last.shape}\")\n",
    "print(f\"  X_test_fslope_lfer shape            : {X_test_fslope_lfer.shape}\")\n",
    "print(f\"  y_test_fslope_lfer shape            : {y_test_fslope_lfer.shape}\")\n",
    "print(f\"  TEST RMSE (fslope + LF-ER)          : {test_rmse_fslope_lfer:.3f}\")\n",
    "print(f\"  TEST MAE  (fslope + LF-ER)          : {test_mae_fslope_lfer:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1629bf1-85c8-4d16-aacd-19c7c627e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing serial fslope features for timing comparison...\n",
      "Serial TRAIN (fslope) time: 665.316 seconds\n",
      "Serial TRAIN (fslope) shape: (17731, 171)\n",
      "\n",
      "Parallel TRAIN (fslope) feature extraction completed.\n",
      "Parallel TRAIN (fslope) time: 82.049 seconds\n",
      "Parallel TRAIN (fslope) shape: (17731, 171)\n",
      "Shape check: OK (serial and parallel outputs have the same shape).\n",
      "Column check: OK (serial and parallel outputs have the same columns).\n"
     ]
    }
   ],
   "source": [
    "# Cell 24 – Parallel TRAIN feature extraction for fslope (HPC variant)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def generate_rolling_features_fslope_parallel(\n",
    "    df,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    "    n_jobs=-1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parallel version of generate_rolling_features_fslope for fslope-only pipeline.\n",
    "\n",
    "    Strategy:\n",
    "      - Split the full DataFrame by unit_nr.\n",
    "      - For each unit, run generate_rolling_features_for_unit_fslope(...) in parallel.\n",
    "      - Concatenate all per-unit feature DataFrames.\n",
    "      - Sort by unit_nr and time_cycles for consistency with the serial version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Full labeled dataset (e.g., train_labeled or test_with_dummy_rul),\n",
    "        containing 'unit_nr', 'time_cycles', 'RUL', SENSOR_COLS, SETTING_COLS.\n",
    "    window : int\n",
    "        Sliding window length.\n",
    "    stride : int\n",
    "        Sliding window step.\n",
    "    epsilon : float\n",
    "        Small constant for fslope normalization.\n",
    "    n_jobs : int\n",
    "        Number of parallel workers (use -1 for all available cores).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_all : pd.DataFrame\n",
    "        Concatenation of per-unit features, sorted by unit_nr and time_cycles.\n",
    "    \"\"\"\n",
    "    # Group once to avoid repeated grouping inside Parallel\n",
    "    grouped_units = list(df.groupby(\"unit_nr\"))\n",
    "\n",
    "    # Run per-unit feature extraction in parallel\n",
    "    results = Parallel(n_jobs=n_jobs, backend=\"loky\")(\n",
    "        delayed(generate_rolling_features_for_unit_fslope)(\n",
    "            df_unit,\n",
    "            window=window,\n",
    "            stride=stride,\n",
    "            epsilon=epsilon,\n",
    "        )\n",
    "        for unit_id, df_unit in grouped_units\n",
    "    )\n",
    "\n",
    "    # Filter out empty DataFrames (units with too few cycles)\n",
    "    non_empty = [r for r in results if r is not None and not r.empty]\n",
    "    if not non_empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    features_all = pd.concat(non_empty, axis=0, ignore_index=True)\n",
    "    features_all = features_all.sort_values([\"unit_nr\", \"time_cycles\"]).reset_index(drop=True)\n",
    "    return features_all\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Benchmark: serial vs parallel TRAIN fslope feature extraction\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# If you already ran the serial fslope extraction earlier, we will reuse\n",
    "# its timing; otherwise we recompute it here for a fair comparison.\n",
    "if \"train_features_fslope\" not in globals():\n",
    "    print(\"Serial fslope features not found in memory – recomputing for comparison...\")\n",
    "    start_serial = time.time()\n",
    "    train_features_fslope = generate_rolling_features_fslope(\n",
    "        train_labeled,\n",
    "        window=WINDOW_SIZE,\n",
    "        stride=STRIDE,\n",
    "        epsilon=EPSILON,\n",
    "    )\n",
    "    end_serial = time.time()\n",
    "    fslope_train_time = end_serial - start_serial\n",
    "else:\n",
    "    print(\"Using existing serial fslope features for timing comparison...\")\n",
    "\n",
    "print(f\"Serial TRAIN (fslope) time: {fslope_train_time:.3f} seconds\")\n",
    "print(f\"Serial TRAIN (fslope) shape: {train_features_fslope.shape}\")\n",
    "\n",
    "# Now run the parallel version\n",
    "start_parallel = time.time()\n",
    "train_features_fslope_parallel = generate_rolling_features_fslope_parallel(\n",
    "    train_labeled,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    "    n_jobs=-1,   # use all available cores\n",
    ")\n",
    "end_parallel = time.time()\n",
    "fslope_train_time_parallel = end_parallel - start_parallel\n",
    "\n",
    "print(\"\\nParallel TRAIN (fslope) feature extraction completed.\")\n",
    "print(f\"Parallel TRAIN (fslope) time: {fslope_train_time_parallel:.3f} seconds\")\n",
    "print(f\"Parallel TRAIN (fslope) shape: {train_features_fslope_parallel.shape}\")\n",
    "\n",
    "# Optional sanity check: shapes and columns should match\n",
    "if train_features_fslope.shape == train_features_fslope_parallel.shape:\n",
    "    print(\"Shape check: OK (serial and parallel outputs have the same shape).\")\n",
    "else:\n",
    "    print(\"WARNING: Shape mismatch between serial and parallel fslope features!\")\n",
    "    \n",
    "if list(train_features_fslope.columns) == list(train_features_fslope_parallel.columns):\n",
    "    print(\"Column check: OK (serial and parallel outputs have the same columns).\")\n",
    "else:\n",
    "    print(\"WARNING: Column mismatch between serial and parallel fslope features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92143b3f-2f97-42be-8b08-da9691b33219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing serial TEST (fslope) features for timing comparison...\n",
      "Serial TEST (fslope) time : 383.331 seconds\n",
      "Serial TEST (fslope) shape: (10196, 171)\n",
      "\n",
      "Parallel TEST (fslope) feature extraction completed.\n",
      "Parallel TEST (fslope) time : 48.699 seconds\n",
      "Parallel TEST (fslope) shape: (10196, 171)\n",
      "Shape check: OK (serial and parallel TEST outputs have the same shape).\n",
      "Column check: OK (serial and parallel TEST outputs have the same columns).\n"
     ]
    }
   ],
   "source": [
    "# Cell 25 – Parallel TEST feature extraction for fslope (HPC variant)\n",
    "\n",
    "from joblib import Parallel, delayed  # safe even if already imported\n",
    "\n",
    "# Reuse add_dummy_rul from earlier; redefine defensively if needed\n",
    "try:\n",
    "    add_dummy_rul\n",
    "except NameError:\n",
    "    def add_dummy_rul(test_df):\n",
    "        df = test_df.copy()\n",
    "        df[\"RUL\"] = 0\n",
    "        return df\n",
    "\n",
    "# Ensure we have test_with_dummy_rul\n",
    "if \"test_with_dummy_rul\" not in globals():\n",
    "    test_with_dummy_rul = add_dummy_rul(test_raw)\n",
    "\n",
    "# If we already have serial fslope TEST features/timing, reuse them; otherwise compute\n",
    "if \"test_features_fslope_full\" not in globals() or \"fslope_test_time\" not in globals():\n",
    "    print(\"Serial TEST (fslope) features not found in memory – recomputing for comparison...\")\n",
    "    start_serial_test = time.time()\n",
    "    test_features_fslope_full = generate_rolling_features_fslope(\n",
    "        test_with_dummy_rul,\n",
    "        window=WINDOW_SIZE,\n",
    "        stride=STRIDE,\n",
    "        epsilon=EPSILON,\n",
    "    )\n",
    "    end_serial_test = time.time()\n",
    "    fslope_test_time = end_serial_test - start_serial_test\n",
    "else:\n",
    "    print(\"Using existing serial TEST (fslope) features for timing comparison...\")\n",
    "\n",
    "print(f\"Serial TEST (fslope) time : {fslope_test_time:.3f} seconds\")\n",
    "print(f\"Serial TEST (fslope) shape: {test_features_fslope_full.shape}\")\n",
    "\n",
    "# Now run the parallel version on TEST\n",
    "start_parallel_test = time.time()\n",
    "test_features_fslope_full_parallel = generate_rolling_features_fslope_parallel(\n",
    "    test_with_dummy_rul,\n",
    "    window=WINDOW_SIZE,\n",
    "    stride=STRIDE,\n",
    "    epsilon=EPSILON,\n",
    "    n_jobs=-1,   # all cores\n",
    ")\n",
    "end_parallel_test = time.time()\n",
    "fslope_test_time_parallel = end_parallel_test - start_parallel_test\n",
    "\n",
    "print(\"\\nParallel TEST (fslope) feature extraction completed.\")\n",
    "print(f\"Parallel TEST (fslope) time : {fslope_test_time_parallel:.3f} seconds\")\n",
    "print(f\"Parallel TEST (fslope) shape: {test_features_fslope_full_parallel.shape}\")\n",
    "\n",
    "# Sanity checks: shapes & columns\n",
    "if test_features_fslope_full.shape == test_features_fslope_full_parallel.shape:\n",
    "    print(\"Shape check: OK (serial and parallel TEST outputs have the same shape).\")\n",
    "else:\n",
    "    print(\"WARNING: Shape mismatch between serial and parallel TEST fslope features!\")\n",
    "\n",
    "if list(test_features_fslope_full.columns) == list(test_features_fslope_full_parallel.columns):\n",
    "    print(\"Column check: OK (serial and parallel TEST outputs have the same columns).\")\n",
    "else:\n",
    "    print(\"WARNING: Column mismatch between serial and parallel TEST fslope features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "396e9959-82ff-40b7-82f6-477d197e388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching current fslope TRAIN/TEST features to Parquet...\n",
      "Saved TRAIN fslope features to: features_train_fslope.parquet\n",
      "Saved TEST  fslope features to: features_test_fslope.parquet\n",
      "\n",
      "Reloading fslope TRAIN/TEST features from Parquet...\n",
      "Loaded TRAIN fslope features from: features_train_fslope.parquet\n",
      "Loaded TEST  fslope features from: features_test_fslope.parquet\n",
      "Cached TRAIN shape: (17731, 171)\n",
      "Cached TEST  shape: (10196, 171)\n"
     ]
    }
   ],
   "source": [
    "# Cell 26 – Parquet caching for fslope features (TRAIN + TEST)\n",
    "\n",
    "import os\n",
    "\n",
    "# Paths where we'll store the cached features\n",
    "FSLOPE_TRAIN_PARQUET = \"features_train_fslope.parquet\"\n",
    "FSLOPE_TEST_PARQUET  = \"features_test_fslope.parquet\"\n",
    "\n",
    "def save_fslope_features_to_parquet(\n",
    "    train_df,\n",
    "    test_df,\n",
    "    train_path=FSLOPE_TRAIN_PARQUET,\n",
    "    test_path=FSLOPE_TEST_PARQUET,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save fslope feature tables (TRAIN and TEST) to Parquet files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pd.DataFrame\n",
    "        TRAIN fslope feature DataFrame.\n",
    "    test_df : pd.DataFrame\n",
    "        TEST fslope feature DataFrame.\n",
    "    train_path : str\n",
    "        File path for TRAIN Parquet.\n",
    "    test_path : str\n",
    "        File path for TEST Parquet.\n",
    "    \"\"\"\n",
    "    train_df.to_parquet(train_path, index=False)\n",
    "    test_df.to_parquet(test_path, index=False)\n",
    "    print(f\"Saved TRAIN fslope features to: {train_path}\")\n",
    "    print(f\"Saved TEST  fslope features to: {test_path}\")\n",
    "\n",
    "\n",
    "def load_fslope_features_from_parquet(\n",
    "    train_path=FSLOPE_TRAIN_PARQUET,\n",
    "    test_path=FSLOPE_TEST_PARQUET,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load fslope feature tables (TRAIN and TEST) from Parquet if they exist.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df, test_df : (pd.DataFrame, pd.DataFrame) or (None, None)\n",
    "        Loaded DataFrames if files exist; otherwise (None, None).\n",
    "    \"\"\"\n",
    "    if not (os.path.exists(train_path) and os.path.exists(test_path)):\n",
    "        print(\"No cached Parquet features found.\")\n",
    "        return None, None\n",
    "\n",
    "    train_df = pd.read_parquet(train_path)\n",
    "    test_df = pd.read_parquet(test_path)\n",
    "    print(f\"Loaded TRAIN fslope features from: {train_path}\")\n",
    "    print(f\"Loaded TEST  fslope features from: {test_path}\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Example usage in this notebook\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Prefer the *parallel* versions if available, otherwise fall back\n",
    "train_fslope_for_cache = (\n",
    "    train_features_fslope_parallel if \"train_features_fslope_parallel\" in globals()\n",
    "    else train_features_fslope\n",
    ")\n",
    "test_fslope_for_cache = (\n",
    "    test_features_fslope_full_parallel if \"test_features_fslope_full_parallel\" in globals()\n",
    "    else test_features_fslope_full\n",
    ")\n",
    "\n",
    "print(\"Caching current fslope TRAIN/TEST features to Parquet...\")\n",
    "save_fslope_features_to_parquet(\n",
    "    train_fslope_for_cache,\n",
    "    test_fslope_for_cache,\n",
    ")\n",
    "\n",
    "# To demonstrate loading (optional sanity check):\n",
    "print(\"\\nReloading fslope TRAIN/TEST features from Parquet...\")\n",
    "train_fslope_cached, test_fslope_cached = load_fslope_features_from_parquet()\n",
    "\n",
    "if train_fslope_cached is not None and test_fslope_cached is not None:\n",
    "    print(f\"Cached TRAIN shape: {train_fslope_cached.shape}\")\n",
    "    print(f\"Cached TEST  shape: {test_fslope_cached.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c03f04a-8387-4bce-8e65-95c03862898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TRAIN fslope features from: features_train_fslope.parquet\n",
      "Loaded TEST  fslope features from: features_test_fslope.parquet\n",
      "Rebuilt fslope design matrices from cached Parquet features.\n",
      "TRAIN: X_fslope shape      : (17731, 168)\n",
      "TRAIN: y_fslope shape      : (17731,)\n",
      "TRAIN: groups_fslope shape : (17731,)\n",
      "TEST : X_test_fslope shape : (10196, 168)\n",
      "TEST : y_test_fslope shape : (10196,)\n",
      "# features (fslope)        : 168\n"
     ]
    }
   ],
   "source": [
    "# Cell 27 – Reload fslope features from Parquet and rebuild X, y, groups\n",
    "\n",
    "# Make sure the helper and paths exist (from Cell 26); redefine defensively if needed\n",
    "import os\n",
    "\n",
    "try:\n",
    "    FSLOPE_TRAIN_PARQUET\n",
    "    FSLOPE_TEST_PARQUET\n",
    "except NameError:\n",
    "    FSLOPE_TRAIN_PARQUET = \"features_train_fslope.parquet\"\n",
    "    FSLOPE_TEST_PARQUET  = \"features_test_fslope.parquet\"\n",
    "\n",
    "def load_fslope_features_from_parquet(\n",
    "    train_path=FSLOPE_TRAIN_PARQUET,\n",
    "    test_path=FSLOPE_TEST_PARQUET,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load fslope feature tables (TRAIN and TEST) from Parquet if they exist.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df, test_df : (pd.DataFrame, pd.DataFrame) or (None, None)\n",
    "        Loaded DataFrames if files exist; otherwise (None, None).\n",
    "    \"\"\"\n",
    "    if not (os.path.exists(train_path) and os.path.exists(test_path)):\n",
    "        print(\"No cached Parquet features found.\")\n",
    "        return None, None\n",
    "\n",
    "    train_df = pd.read_parquet(train_path)\n",
    "    test_df = pd.read_parquet(test_path)\n",
    "    print(f\"Loaded TRAIN fslope features from: {train_path}\")\n",
    "    print(f\"Loaded TEST  fslope features from: {test_path}\")\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Reload cached fslope features\n",
    "# -------------------------------------------------------------------\n",
    "train_fslope_cached, test_fslope_cached = load_fslope_features_from_parquet()\n",
    "\n",
    "if train_fslope_cached is None or test_fslope_cached is None:\n",
    "    print(\"Cannot rebuild X/y/groups from cache – Parquet files are missing.\")\n",
    "else:\n",
    "    # Rebuild feature columns (exclude ID/label columns)\n",
    "    non_feature_cols_fslope = [\"unit_nr\", \"time_cycles\", \"RUL\"]\n",
    "    feature_cols_fslope = [\n",
    "        c for c in train_fslope_cached.columns\n",
    "        if c not in non_feature_cols_fslope\n",
    "    ]\n",
    "\n",
    "    # TRAIN design matrix\n",
    "    X_fslope = train_fslope_cached[feature_cols_fslope].values\n",
    "    y_fslope = train_fslope_cached[\"RUL\"].values\n",
    "    groups_fslope = train_fslope_cached[\"unit_nr\"].values\n",
    "\n",
    "    # TEST design matrix\n",
    "    X_test_fslope = test_fslope_cached[feature_cols_fslope].values\n",
    "    # For test, the cached fslope features may still have dummy RUL;\n",
    "    # if you want true RULs, you can overwrite from rul_test_final later.\n",
    "    # Here we just pull what's in the cached file:\n",
    "    y_test_fslope = test_fslope_cached[\"RUL\"].values\n",
    "\n",
    "    print(\"Rebuilt fslope design matrices from cached Parquet features.\")\n",
    "    print(f\"TRAIN: X_fslope shape      : {X_fslope.shape}\")\n",
    "    print(f\"TRAIN: y_fslope shape      : {y_fslope.shape}\")\n",
    "    print(f\"TRAIN: groups_fslope shape : {groups_fslope.shape}\")\n",
    "    print(f\"TEST : X_test_fslope shape : {X_test_fslope.shape}\")\n",
    "    print(f\"TEST : y_test_fslope shape : {y_test_fslope.shape}\")\n",
    "    print(f\"# features (fslope)        : {len(feature_cols_fslope)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c86128d-2e0e-4aef-9011-0b354858f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Baseline and Proposed Pipelines:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>CV_RMSE_mean</th>\n",
       "      <th>CV_RMSE_std</th>\n",
       "      <th>CV_MAE_mean</th>\n",
       "      <th>CV_MAE_std</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>Train_feat_time_serial_s</th>\n",
       "      <th>Test_feat_time_serial_s</th>\n",
       "      <th>Train_feat_time_parallel_s</th>\n",
       "      <th>Test_feat_time_parallel_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (stats only)</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>29.009000</td>\n",
       "      <td>21.226000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proposed: stats + fslope</td>\n",
       "      <td>33.301382</td>\n",
       "      <td>2.732285</td>\n",
       "      <td>21.602949</td>\n",
       "      <td>1.369023</td>\n",
       "      <td>22.349753</td>\n",
       "      <td>17.190367</td>\n",
       "      <td>665.316446</td>\n",
       "      <td>383.331138</td>\n",
       "      <td>82.048785</td>\n",
       "      <td>48.699486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proposed: stats + LF-ER</td>\n",
       "      <td>37.637002</td>\n",
       "      <td>3.169968</td>\n",
       "      <td>25.186698</td>\n",
       "      <td>1.612716</td>\n",
       "      <td>27.919778</td>\n",
       "      <td>20.035334</td>\n",
       "      <td>691.600941</td>\n",
       "      <td>395.505026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Proposed: stats + fslope + LF-ER</td>\n",
       "      <td>33.089605</td>\n",
       "      <td>2.984159</td>\n",
       "      <td>21.574733</td>\n",
       "      <td>1.302642</td>\n",
       "      <td>23.241497</td>\n",
       "      <td>17.622917</td>\n",
       "      <td>809.752789</td>\n",
       "      <td>451.988945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Pipeline  CV_RMSE_mean  CV_RMSE_std  CV_MAE_mean  \\\n",
       "0             Baseline (stats only)     39.900000     3.100000    27.300000   \n",
       "1          Proposed: stats + fslope     33.301382     2.732285    21.602949   \n",
       "2           Proposed: stats + LF-ER     37.637002     3.169968    25.186698   \n",
       "3  Proposed: stats + fslope + LF-ER     33.089605     2.984159    21.574733   \n",
       "\n",
       "   CV_MAE_std  Test_RMSE   Test_MAE  Train_feat_time_serial_s  \\\n",
       "0    1.800000  29.009000  21.226000                       NaN   \n",
       "1    1.369023  22.349753  17.190367                665.316446   \n",
       "2    1.612716  27.919778  20.035334                691.600941   \n",
       "3    1.302642  23.241497  17.622917                809.752789   \n",
       "\n",
       "   Test_feat_time_serial_s  Train_feat_time_parallel_s  \\\n",
       "0                      NaN                         NaN   \n",
       "1               383.331138                   82.048785   \n",
       "2               395.505026                         NaN   \n",
       "3               451.988945                         NaN   \n",
       "\n",
       "   Test_feat_time_parallel_s  \n",
       "0                        NaN  \n",
       "1                  48.699486  \n",
       "2                        NaN  \n",
       "3                        NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 28 – Summary table of all pipelines (Baseline vs Proposed)\n",
    "\n",
    "# If numpy/pandas aren't in scope for some reason, re-import (safe)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Baseline metrics (from your baseline notebook / earlier notes)\n",
    "#    You can tweak these if you rerun the baseline.\n",
    "# -------------------------------------------------------------------\n",
    "baseline_cv_rmse_mean = 39.9\n",
    "baseline_cv_rmse_std  = 3.1\n",
    "baseline_cv_mae_mean  = 27.3\n",
    "baseline_cv_mae_std   = 1.8\n",
    "\n",
    "baseline_test_rmse = 29.009\n",
    "baseline_test_mae  = 21.226\n",
    "\n",
    "# If you know baseline feature extraction times from the baseline notebook,\n",
    "# you can plug them in here; otherwise we keep them as NaN.\n",
    "baseline_train_time_serial = np.nan   # e.g. replace with your baseline_train_time\n",
    "baseline_test_time_serial  = np.nan   # e.g. replace with your baseline_test_time\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Collect metrics for each pipeline\n",
    "# -------------------------------------------------------------------\n",
    "rows = []\n",
    "\n",
    "# Baseline (stats only)\n",
    "rows.append({\n",
    "    \"Pipeline\": \"Baseline (stats only)\",\n",
    "    \"CV_RMSE_mean\": baseline_cv_rmse_mean,\n",
    "    \"CV_RMSE_std\":  baseline_cv_rmse_std,\n",
    "    \"CV_MAE_mean\":  baseline_cv_mae_mean,\n",
    "    \"CV_MAE_std\":   baseline_cv_mae_std,\n",
    "    \"Test_RMSE\":    baseline_test_rmse,\n",
    "    \"Test_MAE\":     baseline_test_mae,\n",
    "    \"Train_feat_time_serial_s\": baseline_train_time_serial,\n",
    "    \"Test_feat_time_serial_s\":  baseline_test_time_serial,\n",
    "    \"Train_feat_time_parallel_s\": np.nan,\n",
    "    \"Test_feat_time_parallel_s\":  np.nan,\n",
    "})\n",
    "\n",
    "# Proposed: Baseline + fslope\n",
    "rows.append({\n",
    "    \"Pipeline\": \"Proposed: stats + fslope\",\n",
    "    \"CV_RMSE_mean\": rmse_mean_fslope,\n",
    "    \"CV_RMSE_std\":  rmse_std_fslope,\n",
    "    \"CV_MAE_mean\":  mae_mean_fslope,\n",
    "    \"CV_MAE_std\":   mae_std_fslope,\n",
    "    \"Test_RMSE\":    test_rmse_fslope,\n",
    "    \"Test_MAE\":     test_mae_fslope,\n",
    "    \"Train_feat_time_serial_s\":   fslope_train_time,\n",
    "    \"Test_feat_time_serial_s\":    fslope_test_time,\n",
    "    \"Train_feat_time_parallel_s\": fslope_train_time_parallel,\n",
    "    \"Test_feat_time_parallel_s\":  fslope_test_time_parallel,\n",
    "})\n",
    "\n",
    "# Proposed: Baseline + LF-ER\n",
    "rows.append({\n",
    "    \"Pipeline\": \"Proposed: stats + LF-ER\",\n",
    "    \"CV_RMSE_mean\": rmse_mean_lfer,\n",
    "    \"CV_RMSE_std\":  rmse_std_lfer,\n",
    "    \"CV_MAE_mean\":  mae_mean_lfer,\n",
    "    \"CV_MAE_std\":   mae_std_lfer,\n",
    "    \"Test_RMSE\":    test_rmse_lfer,\n",
    "    \"Test_MAE\":     test_mae_lfer,\n",
    "    \"Train_feat_time_serial_s\":   lfer_train_time,\n",
    "    \"Test_feat_time_serial_s\":    lfer_test_time,\n",
    "    \"Train_feat_time_parallel_s\": np.nan,\n",
    "    \"Test_feat_time_parallel_s\":  np.nan,\n",
    "})\n",
    "\n",
    "# Proposed: Baseline + fslope + LF-ER\n",
    "rows.append({\n",
    "    \"Pipeline\": \"Proposed: stats + fslope + LF-ER\",\n",
    "    \"CV_RMSE_mean\": rmse_mean_fslope_lfer,\n",
    "    \"CV_RMSE_std\":  rmse_std_fslope_lfer,\n",
    "    \"CV_MAE_mean\":  mae_mean_fslope_lfer,\n",
    "    \"CV_MAE_std\":   mae_std_fslope_lfer,\n",
    "    \"Test_RMSE\":    test_rmse_fslope_lfer,\n",
    "    \"Test_MAE\":     test_mae_fslope_lfer,\n",
    "    \"Train_feat_time_serial_s\":   fslope_lfer_train_time,\n",
    "    \"Test_feat_time_serial_s\":    fslope_lfer_test_time,\n",
    "    \"Train_feat_time_parallel_s\": np.nan,\n",
    "    \"Test_feat_time_parallel_s\":  np.nan,\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "# Nice ordering of columns\n",
    "summary_df = summary_df[\n",
    "    [\n",
    "        \"Pipeline\",\n",
    "        \"CV_RMSE_mean\", \"CV_RMSE_std\",\n",
    "        \"CV_MAE_mean\",  \"CV_MAE_std\",\n",
    "        \"Test_RMSE\",    \"Test_MAE\",\n",
    "        \"Train_feat_time_serial_s\", \"Test_feat_time_serial_s\",\n",
    "        \"Train_feat_time_parallel_s\", \"Test_feat_time_parallel_s\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(\"Summary of Baseline and Proposed Pipelines:\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea1dd7-6de2-46af-b257-e655ca99e77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
